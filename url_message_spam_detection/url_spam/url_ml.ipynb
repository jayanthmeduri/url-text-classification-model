{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c727f3d-a657-40d0-9e27-d1964f438551",
   "metadata": {},
   "source": [
    "### import pandas as pd \n",
    "df = pd.read_csv(\"C:\\\\Users\\\\jayan\\\\OneDrive\\\\Documents\\\\finalyearproject\\\\url_spam_classification.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "d07a47fa-39ab-4c21-a497-ebc3eee05045",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(keep = 'first')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "3562a0b2-d891-4b4b-a8d0-d2c8daed5964",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(87581, 2)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "d873d35f-808b-40bd-9dc1-5ffa6219f951",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "df['target'] = encoder.fit_transform(df['is_spam'])\n",
    "\n",
    "df = df.drop('is_spam', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "e10940b1-f14d-4502-9bbd-dc8b940ce3c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of                                                       url  target\n",
       "0       https://briefingday.us8.list-manage.com/unsubs...       1\n",
       "1                                  https://www.hvper.com/       1\n",
       "2                      https://briefingday.com/m/v4n3i4f3       1\n",
       "3        https://briefingday.com/n/20200618/m#commentform       0\n",
       "4                             https://briefingday.com/fan       1\n",
       "...                                                   ...     ...\n",
       "148287  https://numlock.substack.com/p/numlock-news-de...       0\n",
       "148288  https://numlock.substack.com/p/numlock-news-de...       0\n",
       "148290  https://www.hollywoodreporter.com/news/2020-bo...       0\n",
       "148294  https://apnews.com/article/seoul-south-korea-n...       0\n",
       "148297  https://www.wsj.com/articles/the-philadelphia-...       0\n",
       "\n",
       "[87581 rows x 2 columns]>"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "ebe44654-8f11-4ed5-aa21-5427382fd631",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import urllib.parse\n",
    "import math\n",
    "\n",
    "# Feature extraction function\n",
    "def extract_url_features(url):\n",
    "    # Parse the URL\n",
    "    parsed_url = urllib.parse.urlparse(url)\n",
    "    \n",
    "    features = {}\n",
    "    \n",
    "    # 1. url-length: Number of characters in the URL\n",
    "    features['url_length'] = len(url)\n",
    "    \n",
    "    # 2. has_subscribe: Whether the URL contains the word 'subscribe'\n",
    "    features['has_subscribe'] = int('subscribe' in url.lower())\n",
    "    \n",
    "    # 3. contains_hash: Whether the URL contains the hash '#' symbol\n",
    "    features['contains_hash'] = int('#' in url)\n",
    "    \n",
    "    # 4. num_digits: The number of digits in the URL\n",
    "    features['num_digits'] = len(re.findall(r'\\d', url))\n",
    "    \n",
    "    # 5. non_https: Whether the URL uses a non-HTTPS connection\n",
    "    features['non_https'] = int(parsed_url.scheme != 'https')\n",
    "    \n",
    "    # 6. num_words: The number of words in the URL (split by '/' and '-')\n",
    "    features['num_words'] = len(re.findall(r'[\\w]+', parsed_url.path))\n",
    "    \n",
    "    # 7. entropy: Measure of entropy (disorder/uncertainty) in the URL\n",
    "    def calculate_entropy(url):\n",
    "        # Frequency of each character\n",
    "        prob = [float(url.count(c)) / len(url) for c in set(url)]\n",
    "        # Shannon entropy formula\n",
    "        entropy = -sum([p * math.log2(p) for p in prob])\n",
    "        return entropy\n",
    "    \n",
    "    features['entropy'] = calculate_entropy(url)\n",
    "    \n",
    "    # 8. num_params: Number of query parameters in the URL\n",
    "    query_params = urllib.parse.parse_qs(parsed_url.query)\n",
    "    features['num_params'] = len(query_params)\n",
    "    \n",
    "    # 9. num_fragments: Number of fragments in the URL (after '#')\n",
    "    features['num_fragments'] = len(parsed_url.fragment.split('&')) if parsed_url.fragment else 0\n",
    "    \n",
    "    # 10. num_subdomains: Number of subdomains (split by '.')\n",
    "    features['num_subdomains'] = len(parsed_url.netloc.split('.')) - 2  # -2 for 'domain' and 'tld'\n",
    "    \n",
    "    # 11. num_%20: Number of encoded white spaces ('%20') in the URL\n",
    "    features['num_%20'] = url.count('%20')\n",
    "    \n",
    "    # 12. num_@: Number of '@' symbols in the URL\n",
    "    features['num_@'] = url.count('@')\n",
    "    \n",
    "    # 13. has_ip: Check if the URL has an IP address instead of a domain name\n",
    "    ip_pattern = re.compile(r'(\\d{1,3}\\.){3}\\d{1,3}')  # Pattern to match IP addresses\n",
    "    features['has_ip'] = int(bool(ip_pattern.search(parsed_url.netloc)))\n",
    "    \n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "a9721be8-9925-4592-acee-75aff75c831b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['features'] = df['url'].apply(extract_url_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "5150ecf9-9979-409c-ac08-449b3834b98b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>target</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://briefingday.us8.list-manage.com/unsubs...</td>\n",
       "      <td>1</td>\n",
       "      <td>{'url_length': 51, 'has_subscribe': 1, 'contai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.hvper.com/</td>\n",
       "      <td>1</td>\n",
       "      <td>{'url_length': 22, 'has_subscribe': 0, 'contai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://briefingday.com/m/v4n3i4f3</td>\n",
       "      <td>1</td>\n",
       "      <td>{'url_length': 34, 'has_subscribe': 0, 'contai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://briefingday.com/n/20200618/m#commentform</td>\n",
       "      <td>0</td>\n",
       "      <td>{'url_length': 48, 'has_subscribe': 0, 'contai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://briefingday.com/fan</td>\n",
       "      <td>1</td>\n",
       "      <td>{'url_length': 27, 'has_subscribe': 0, 'contai...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  target  \\\n",
       "0  https://briefingday.us8.list-manage.com/unsubs...       1   \n",
       "1                             https://www.hvper.com/       1   \n",
       "2                 https://briefingday.com/m/v4n3i4f3       1   \n",
       "3   https://briefingday.com/n/20200618/m#commentform       0   \n",
       "4                        https://briefingday.com/fan       1   \n",
       "\n",
       "                                            features  \n",
       "0  {'url_length': 51, 'has_subscribe': 1, 'contai...  \n",
       "1  {'url_length': 22, 'has_subscribe': 0, 'contai...  \n",
       "2  {'url_length': 34, 'has_subscribe': 0, 'contai...  \n",
       "3  {'url_length': 48, 'has_subscribe': 0, 'contai...  \n",
       "4  {'url_length': 27, 'has_subscribe': 0, 'contai...  "
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664ab352-bd79-403e-9292-cabd81805105",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "89c95980-2fa9-4360-8626-5d3f3cd35a5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       url_length  has_subscribe  contains_hash  num_digits  non_https  \\\n",
      "0              51              1              0           1          0   \n",
      "1              22              0              0           0          0   \n",
      "2              34              0              0           4          0   \n",
      "3              48              0              1           8          0   \n",
      "4              27              0              0           0          0   \n",
      "...           ...            ...            ...         ...        ...   \n",
      "87576          68              0              0           6          0   \n",
      "87577          77              0              0           6          0   \n",
      "87578          97              0              0           6          0   \n",
      "87579         113              0              0          24          0   \n",
      "87580         112              0              0          11          0   \n",
      "\n",
      "       num_words   entropy  num_params  num_fragments  num_subdomains  \\\n",
      "0              1  4.385195           0              0               2   \n",
      "1              0  3.663533           0              0               1   \n",
      "2              2  4.359378           0              0               0   \n",
      "3              3  4.454987           0              1               0   \n",
      "4              1  4.208410           0              0               0   \n",
      "...          ...       ...         ...            ...             ...   \n",
      "87576          7  4.449842           0              0               1   \n",
      "87577          8  4.394644           0              0               1   \n",
      "87578         12  4.457275           0              0               1   \n",
      "87579         11  4.708181           0              0               0   \n",
      "87580         13  4.598719           0              0               1   \n",
      "\n",
      "       num_%20  num_@  has_ip  \n",
      "0            0      0       0  \n",
      "1            0      0       0  \n",
      "2            0      0       0  \n",
      "3            0      0       0  \n",
      "4            0      0       0  \n",
      "...        ...    ...     ...  \n",
      "87576        0      0       0  \n",
      "87577        0      0       0  \n",
      "87578        0      0       0  \n",
      "87579        0      0       0  \n",
      "87580        0      0       0  \n",
      "\n",
      "[87581 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "X = pd.json_normalize(df['features'])\n",
    "\n",
    "print(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "55d44696-ce24-416f-8d5f-9b8365c3a9ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9682023177484729\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98     16956\n",
      "           1       0.51      0.19      0.28       561\n",
      "\n",
      "    accuracy                           0.97     17517\n",
      "   macro avg       0.74      0.59      0.63     17517\n",
      "weighted avg       0.96      0.97      0.96     17517\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Step 1: Assuming 'X' is already your feature matrix and 'y' is your target column\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "X = pd.json_normalize(df['features'])\n",
    "\n",
    "y = df['target']\n",
    "# Step 2: Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 3: Initialize BaggingClassifier with DecisionTreeClassifier as the base estimator\n",
    "bagging_clf = BaggingClassifier(estimator=DecisionTreeClassifier(), n_estimators=50, random_state=42)\n",
    "\n",
    "# Step 4: Fit the model to the training data\n",
    "bagging_clf.fit(X_train, y_train)\n",
    "\n",
    "# Step 5: Make predictions on the test data\n",
    "y_pred = bagging_clf.predict(X_test)\n",
    "\n",
    "# Step 6: Evaluate the model performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "# Step 7: Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9bcaea34-9d49-4727-9354-235c9670723f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# 2. Support Vector Machine (SVM)\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# 3. K-Nearest Neighbors (KNN)\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# 4. Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# 5. Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# 6. Gradient Boosting Machines (GBM)\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# 7. XGBoost\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# 8. LightGBM\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# 9. CatBoost\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# 10. Naive Bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# 11. Linear Discriminant Analysis (LDA)\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "# 12. Quadratic Discriminant Analysis (QDA)\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "# 13. AdaBoost\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# 14. Extra Trees\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "# 15. Stacking\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "# 16. Voting Classifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# 17. Principal Component Analysis (PCA) for dimensionality reduction\n",
    "from sklearn.decomposition import PCA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9bafb2e5-c401-499e-8608-9dcd496632c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "classifiers = {}\n",
    "\n",
    "# 1. Logistic Regression\n",
    "classifiers['log_reg'] = LogisticRegression(random_state=42)\n",
    "\n",
    "# 2. Support Vector Machine (SVM)\n",
    "classifiers['svc'] = SVC(kernel='sigmoid', gamma=1.0)\n",
    "\n",
    "# 3. K-Nearest Neighbors (KNN)\n",
    "classifiers['knn'] = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# 4. Decision Tree\n",
    "classifiers['decision_tree'] = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# 5. Random Forest\n",
    "classifiers['random_forest'] = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# 6. Gradient Boosting Machines (GBM)\n",
    "classifiers['gb'] = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# 7. XGBoost\n",
    "classifiers['xgb'] = XGBClassifier(random_state=42)\n",
    "\n",
    "# 8. LightGBM\n",
    "classifiers['lgb'] = LGBMClassifier(random_state=42)\n",
    "\n",
    "# 9. CatBoost\n",
    "classifiers['catboost'] = CatBoostClassifier(random_state=42, verbose=0)\n",
    "\n",
    "# 10. Naive Bayes\n",
    "classifiers['naive_bayes'] = GaussianNB()\n",
    "\n",
    "# 11. Linear Discriminant Analysis (LDA)\n",
    "classifiers['lda'] = LinearDiscriminantAnalysis()\n",
    "\n",
    "# 12. Quadratic Discriminant Analysis (QDA)\n",
    "classifiers['qda'] = QuadraticDiscriminantAnalysis()\n",
    "\n",
    "# 13. AdaBoost\n",
    "classifiers['ada'] = AdaBoostClassifier(random_state=42)\n",
    "\n",
    "# 14. Extra Trees\n",
    "classifiers['extra_trees'] = ExtraTreesClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2525d93-876a-4a36-b8a7-be22959cfc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "def create_stacking_classifier():\n",
    "    # Base estimators\n",
    "    base_estimators = [\n",
    "        ('log_reg', LogisticRegression(random_state=42)),\n",
    "        ('svc', SVC(kernel='sigmoid', gamma=1.0)),\n",
    "        ('knn', KNeighborsClassifier(n_neighbors=5)),\n",
    "        ('random_forest', RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "    ]\n",
    "\n",
    "    # Final estimator\n",
    "    final_estimator = LogisticRegression(random_state=42)\n",
    "\n",
    "    # Stacking Classifier\n",
    "    stacking_clf = StackingClassifier(estimators=base_estimators, final_estimator=final_estimator, cv=5)\n",
    "\n",
    "    return stacking_clf\n",
    "\n",
    "# Example of using the function\n",
    "stacking_classifier = create_stacking_classifier()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1deabb9b-6724-4d83-b71b-5557d8357752",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_voting_classifier():\n",
    "    # Create base classifiers\n",
    "    base_estimators = [\n",
    "        ('log_reg', LogisticRegression(random_state=42)),\n",
    "        ('svc', SVC(kernel='sigmoid', gamma=1.0, probability=True)),  # Set probability=True for soft voting\n",
    "        ('knn', KNeighborsClassifier(n_neighbors=5)),\n",
    "        ('random_forest', RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "    ]\n",
    "\n",
    "    # Create Voting Classifier (soft voting)\n",
    "    voting_clf = VotingClassifier(estimators=base_estimators, voting='soft')\n",
    "\n",
    "    return voting_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8fc71157-5dad-4454-be6d-18dcbe50874f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model successfully pickled as 'voting_classifier.pkl'.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "# Create the voting classifier\n",
    "voting_clf_model = create_voting_classifier()\n",
    "\n",
    "# Save the model to a .pkl file\n",
    "with open('voting_classifier.pkl', 'wb') as file:\n",
    "    pickle.dump(voting_clf_model, file)\n",
    "\n",
    "print(\"Model successfully pickled as 'voting_classifier.pkl'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "8e67385f-76ee-4e3a-ad63-c3a5d6c0f84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "clfs = {\n",
    "    'SVC': svc,\n",
    "    'Logistic Regression': LogisticRegression(random_state=42),\n",
    "    'KNN': KNeighborsClassifier(n_neighbors=5),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
    "    'XGBoost': XGBClassifier(random_state=42),\n",
    "    'LightGBM': LGBMClassifier(random_state=42),\n",
    "    'CatBoost': CatBoostClassifier(random_state=42, verbose=0),\n",
    "    'Naive Bayes': GaussianNB(),\n",
    "    'LDA': LinearDiscriminantAnalysis(),\n",
    "    'QDA': QuadraticDiscriminantAnalysis(),\n",
    "    'AdaBoost': AdaBoostClassifier(random_state=42),\n",
    "    'Extra Trees': ExtraTreesClassifier(n_estimators=100, random_state=42),\n",
    "    'Stacking': create_stacking_classifier(),\n",
    "    'Voting Classifier': create_voting_classifier(),\n",
    "    # Assuming you have the create_stacking_classifier function defined\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "37a1446b-bb7a-4a1a-a893-da7ed37561a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier(clf,X_train,y_train,X_test,y_test):\n",
    "    clf.fit(X_train,y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test,y_pred)\n",
    "    precision = precision_score(y_test,y_pred)\n",
    "    \n",
    "    return accuracy,precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97917b1-979a-46ba-9188-8cad58bb6d6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "acc7402c-4ac2-4a4d-ac6b-0c8189809c6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jayan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For  SVC\n",
      "Accuracy -  0.9679739681452304\n",
      "Precision -  0.0\n",
      "For  Logistic Regression\n",
      "Accuracy -  0.9714562995946795\n",
      "Precision -  0.9295774647887324\n",
      "For  KNN\n",
      "Accuracy -  0.969458240566307\n",
      "Precision -  0.6031746031746031\n",
      "For  Decision Tree\n",
      "Accuracy -  0.9537021179425701\n",
      "Precision -  0.24279835390946503\n",
      "For  Random Forest\n",
      "Accuracy -  0.9679739681452304\n",
      "Precision -  0.5\n",
      "For  Gradient Boosting\n",
      "Accuracy -  0.9719700862019752\n",
      "Precision -  0.8977272727272727\n",
      "For  XGBoost\n",
      "Accuracy -  0.9726551350117029\n",
      "Precision -  0.91\n",
      "[LightGBM] [Info] Number of positive: 2224, number of negative: 67840\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007269 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 642\n",
      "[LightGBM] [Info] Number of data points in the train set: 70064, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.031742 -> initscore=-3.417845\n",
      "[LightGBM] [Info] Start training from score -3.417845\n",
      "For  LightGBM\n",
      "Accuracy -  0.9727122224125135\n",
      "Precision -  0.9029126213592233\n",
      "For  CatBoost\n",
      "Accuracy -  0.9725409602100816\n",
      "Precision -  0.8846153846153846\n",
      "For  Naive Bayes\n",
      "Accuracy -  0.7089684306673517\n",
      "Precision -  0.0806063967461638\n",
      "For  LDA\n",
      "Accuracy -  0.9709996003881943\n",
      "Precision -  0.8354430379746836\n",
      "For  QDA\n",
      "Accuracy -  0.9679739681452304\n",
      "Precision -  0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jayan\\anaconda3\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Users\\jayan\\anaconda3\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Users\\jayan\\anaconda3\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Users\\jayan\\anaconda3\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "C:\\Users\\jayan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\jayan\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For  AdaBoost\n",
      "Accuracy -  0.9712850373922476\n",
      "Precision -  0.8918918918918919\n",
      "For  Extra Trees\n",
      "Accuracy -  0.9649483359022664\n",
      "Precision -  0.40148698884758366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jayan\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jayan\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For  Stacking\n",
      "Accuracy -  0.9717417365987326\n",
      "Precision -  0.83\n",
      "For  Voting Classifier\n",
      "Accuracy -  0.9717417365987326\n",
      "Precision -  1.0\n"
     ]
    }
   ],
   "source": [
    "accuracy_scores = []\n",
    "precision_scores = []\n",
    "\n",
    "for name,clf in clfs.items():\n",
    "    \n",
    "    current_accuracy,current_precision = train_classifier(clf, X_train,y_train,X_test,y_test)\n",
    "    \n",
    "    print(\"For \",name)\n",
    "    print(\"Accuracy - \",current_accuracy)\n",
    "    print(\"Precision - \",current_precision)\n",
    "    \n",
    "    accuracy_scores.append(current_accuracy)\n",
    "    precision_scores.append(current_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "7835e9a5-f18d-477c-b67d-0a2b9033361d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Voting Classifier</td>\n",
       "      <td>0.971742</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.971456</td>\n",
       "      <td>0.929577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.972655</td>\n",
       "      <td>0.910000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.972712</td>\n",
       "      <td>0.902913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.971970</td>\n",
       "      <td>0.897727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.971285</td>\n",
       "      <td>0.891892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.972541</td>\n",
       "      <td>0.884615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LDA</td>\n",
       "      <td>0.971000</td>\n",
       "      <td>0.835443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Stacking</td>\n",
       "      <td>0.971742</td>\n",
       "      <td>0.830000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.969458</td>\n",
       "      <td>0.603175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.967974</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Extra Trees</td>\n",
       "      <td>0.964948</td>\n",
       "      <td>0.401487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.953702</td>\n",
       "      <td>0.242798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.708968</td>\n",
       "      <td>0.080606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.967974</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>QDA</td>\n",
       "      <td>0.967974</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Algorithm  Accuracy  Precision\n",
       "15    Voting Classifier  0.971742   1.000000\n",
       "1   Logistic Regression  0.971456   0.929577\n",
       "6               XGBoost  0.972655   0.910000\n",
       "7              LightGBM  0.972712   0.902913\n",
       "5     Gradient Boosting  0.971970   0.897727\n",
       "12             AdaBoost  0.971285   0.891892\n",
       "8              CatBoost  0.972541   0.884615\n",
       "10                  LDA  0.971000   0.835443\n",
       "14             Stacking  0.971742   0.830000\n",
       "2                   KNN  0.969458   0.603175\n",
       "4         Random Forest  0.967974   0.500000\n",
       "13          Extra Trees  0.964948   0.401487\n",
       "3         Decision Tree  0.953702   0.242798\n",
       "9           Naive Bayes  0.708968   0.080606\n",
       "0                   SVC  0.967974   0.000000\n",
       "11                  QDA  0.967974   0.000000"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance_df = pd.DataFrame({'Algorithm':clfs.keys(),'Accuracy':accuracy_scores,'Precision':precision_scores}).sort_values('Precision',ascending=False)\n",
    "performance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c90826c-b450-4990-a906-7c0a622f6eda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "aaf14475-a6dd-4947-b279-be006e9d6d9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2224, number of negative: 67840\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004550 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 642\n",
      "[LightGBM] [Info] Number of data points in the train set: 70064, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.031742 -> initscore=-3.417845\n",
      "[LightGBM] [Info] Start training from score -3.417845\n",
      "For  Voting Classifier\n",
      "Accuracy -  0.9722555232060285\n",
      "Precision -  0.9746835443037974\n"
     ]
    }
   ],
   "source": [
    "\n",
    "current_accuracy,current_precision = train_classifier(voting_classifier(), X_train,y_train,X_test,y_test)\n",
    "    \n",
    "print(\"For \",name)\n",
    "print(\"Accuracy - \",current_accuracy)\n",
    "print(\"Precision - \",current_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03833ebf-e4f9-4e7e-a342-e53b3efd37cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def voting_classifier():\n",
    "    # Create base classifiers\n",
    "    base_estimators = [\n",
    "        ('log_reg', LogisticRegression(random_state=42)),\n",
    "        ('XGBoost', XGBClassifier(random_state=42)),  # Set probability=True for soft voting\n",
    "        ('LightGBM',LGBMClassifier(random_state=42)),\n",
    "        ('Gradient Boosting', GradientBoostingClassifier(n_estimators=100, random_state=42))\n",
    "    ]\n",
    "\n",
    "    # Create Voting Classifier (soft voting)\n",
    "    voting_clf = VotingClassifier(estimators=base_estimators, voting='hard')\n",
    "\n",
    "    return voting_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21eaba4e-179c-43bc-85bc-649ad2a40c8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ed5f5e-be08-4245-b9ba-30582b1c3ebc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
